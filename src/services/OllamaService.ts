import { AIReportRequest, AIReportResponse, AIReportConfig, GenerateReportResult } from '@/types';
import { validateAiConfig } from '@/utils/aiConfigValidation';

/**
 * Ollama APIæœåŠ¡ç±»
 * æä¾›ä¸OllamaæœåŠ¡å™¨çš„é›†æˆåŠŸèƒ½ï¼Œæ”¯æŒAIæŠ¥å‘Šç”Ÿæˆ
 * æ›´æ–°æ—¶é—´: 2025-08-14 è°ƒè¯•ç‰ˆæœ¬
 */
export class OllamaService {
  private static readonly DEFAULT_TIMEOUT = 300000; // 300ç§’è¶…æ—¶
  private static readonly DEFAULT_STREAM = false;

  /**
   * ç”ŸæˆAIæŠ¥å‘Š
   * @param config AIé…ç½®ï¼ˆURLã€æ¨¡å‹ã€æ¸©åº¦ï¼‰
   * @param prompt æç¤ºè¯
   * @returns ç”Ÿæˆç»“æœ
   */
  static async generateReport(
    config: AIReportConfig,
    prompt: string
  ): Promise<GenerateReportResult> {
    try {
      // éªŒè¯é…ç½®
      const configValidation = validateAiConfig(config);
      if (!configValidation.isValid) {
        return {
          success: false,
          error: configValidation.error || 'é…ç½®éªŒè¯å¤±è´¥'
        };
      }

      // éªŒè¯æç¤ºè¯
      if (!prompt?.trim()) {
        return {
          success: false,
          error: 'æç¤ºè¯ä¸èƒ½ä¸ºç©º'
        };
      }

      // æ„é€ è¯·æ±‚
      const requestData: AIReportRequest = {
        model: config.modelName,
        prompt: prompt.trim(),
        temperature: config.temperature,
        stream: OllamaService.DEFAULT_STREAM
      };

      // å‘é€APIè¯·æ±‚
      const response = await OllamaService.callOllamaAPI(config.ollamaUrl, requestData);
      
      if (!response.success) {
        return response;
      }

      return {
        success: true,
        content: response.content
      };

    } catch (error) {
      console.error('ç”ŸæˆAIæŠ¥å‘Šå¤±è´¥:', error);
      return {
        success: false,
        error: error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'
      };
    }
  }

  /**
   * æµ‹è¯•OllamaæœåŠ¡è¿æ¥
   * @param config AIé…ç½®
   * @returns è¿æ¥æµ‹è¯•ç»“æœ
   */
  static async testConnection(config: AIReportConfig): Promise<GenerateReportResult> {
    try {
      // éªŒè¯é…ç½®
      const configValidation = validateAiConfig(config);
      if (!configValidation.isValid) {
        return {
          success: false,
          error: configValidation.error || 'é…ç½®éªŒè¯å¤±è´¥'
        };
      }

      // é¦–å…ˆæµ‹è¯•æœåŠ¡æ˜¯å¦å¯è¾¾ - ä½¿ç”¨ /api/tags ç«¯ç‚¹
      const tagsTestResult = await OllamaService.testServiceAvailability(config.ollamaUrl);
      if (!tagsTestResult.success) {
        return tagsTestResult;
      }

      // æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨
      const modelCheckResult = await OllamaService.checkModelAvailability(config.ollamaUrl, config.modelName);
      if (!modelCheckResult.success) {
        return modelCheckResult;
      }

      // æœ€åæµ‹è¯•å®é™…ç”ŸæˆåŠŸèƒ½
      const testPrompt = 'è¯·å›å¤"è¿æ¥æµ‹è¯•æˆåŠŸ"';
      
      const requestData: AIReportRequest = {
        model: config.modelName,
        prompt: testPrompt,
        temperature: 0.1,
        stream: false
      };

      const response = await OllamaService.callOllamaAPI(config.ollamaUrl, requestData);
      
      if (response.success) {
        return {
          success: true,
          content: 'è¿æ¥æµ‹è¯•æˆåŠŸ'
        };
      }

      return response;

    } catch (error) {
      console.error('è¿æ¥æµ‹è¯•å¤±è´¥:', error);
      return {
        success: false,
        error: error instanceof Error ? error.message : 'è¿æ¥æµ‹è¯•å¤±è´¥'
      };
    }
  }

  /**
   * æµ‹è¯•æœåŠ¡æ˜¯å¦å¯è¾¾ - æ”¯æŒå¤šç§APIæ ¼å¼
   * @param baseUrl æœåŠ¡å™¨URL
   * @returns æœåŠ¡å¯ç”¨æ€§æµ‹è¯•ç»“æœ
   */
  private static async testServiceAvailability(baseUrl: string): Promise<GenerateReportResult> {
    try {
      // å…ˆå°è¯• OpenAI å…¼å®¹çš„ /v1/models ç«¯ç‚¹
      const openaiUrl = OllamaService.buildOpenAIModelsUrl(baseUrl);
      const openaiResult = await OllamaService.tryFetchWithTimeout(openaiUrl);
      
      if (openaiResult.success) {
        return { success: true, content: 'æœåŠ¡å¯è¾¾ (OpenAI API å…¼å®¹)' };
      }

      // å¦‚æœå¤±è´¥ï¼Œå°è¯•æ ‡å‡†çš„ Ollama /api/tags ç«¯ç‚¹
      const ollamaUrl = OllamaService.buildTagsUrl(baseUrl);
      const ollamaResult = await OllamaService.tryFetchWithTimeout(ollamaUrl);
      
      if (ollamaResult.success) {
        return { success: true, content: 'æœåŠ¡å¯è¾¾ (Ollama API)' };
      }

      // ä¸¤ä¸ªç«¯ç‚¹éƒ½å¤±è´¥
      const suggestions = OllamaService.getConnectionSuggestion(baseUrl);
      return {
        success: false,
        error: `æœåŠ¡ä¸å¯è¾¾ - å·²å°è¯• OpenAI å’Œ Ollama API æ ¼å¼${suggestions}`
      };

    } catch (error) {
      if (error instanceof Error) {
        // å¤„ç†URLæ„å»ºé”™è¯¯
        if (error.message.includes('æ— æ•ˆçš„æœåŠ¡å™¨URL')) {
          return {
            success: false,
            error: error.message
          };
        }
      }
      
      return {
        success: false,
        error: `æœåŠ¡è¿æ¥å¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`
      };
    }
  }

  /**
   * å°è¯•è·å–URLå¹¶å¤„ç†è¶…æ—¶
   * @param url è¦å°è¯•çš„URL
   * @returns è¯·æ±‚ç»“æœ
   */
  private static async tryFetchWithTimeout(url: string): Promise<{ success: boolean; response?: Response; error?: string }> {
    try {
      const controller = new AbortController();
      const timeoutId = setTimeout(() => {
        controller.abort();
      }, 5000);

      const response = await fetch(url, {
        method: 'GET',
        headers: { 'Content-Type': 'application/json' },
        signal: controller.signal
      });

      clearTimeout(timeoutId);
      
      return { success: response.ok, response };
    } catch (error) {
      if (error instanceof Error) {
        if (error.name === 'AbortError') {
          return { success: false, error: 'è¿æ¥è¶…æ—¶' };
        }
        if (error.message.includes('fetch') || error.message.includes('Failed to fetch')) {
          return { success: false, error: 'è¿æ¥å¤±è´¥' };
        }
      }
      return { success: false, error: error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯' };
    }
  }

  /**
   * æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨ - æ”¯æŒå¤šç§APIæ ¼å¼
   * @param baseUrl æœåŠ¡å™¨URL
   * @param modelName æ¨¡å‹åç§°
   * @returns æ¨¡å‹å¯ç”¨æ€§æ£€æŸ¥ç»“æœ
   */
  private static async checkModelAvailability(baseUrl: string, modelName: string): Promise<GenerateReportResult> {
    try {
      // å…ˆå°è¯• OpenAI å…¼å®¹çš„ /v1/models ç«¯ç‚¹
      const openaiUrl = OllamaService.buildOpenAIModelsUrl(baseUrl);
      const openaiResult = await OllamaService.tryFetchWithTimeout(openaiUrl);
      
      if (openaiResult.success && openaiResult.response) {
        const data = await openaiResult.response.json();
        const models = data.data || [];
        
        // OpenAI API æ ¼å¼ï¼šæŸ¥æ‰¾æ¨¡å‹ IDï¼Œæ”¯æŒç²¾ç¡®åŒ¹é…å’Œéƒ¨åˆ†åŒ¹é…
        const modelExists = models.some((model: { id: string }) => {
          return model.id === modelName || 
                 model.id === `${modelName}:latest` ||
                 model.id.startsWith(`${modelName}:`);
        });
        
        if (modelExists) {
          return { success: true, content: 'æ¨¡å‹å¯ç”¨ (OpenAI API)' };
        } else {
          const availableModels = models.map((model: { id: string }) => model.id).join(', ');
          return {
            success: false,
            error: `æ¨¡å‹ '${modelName}' ä¸å­˜åœ¨ã€‚å¯ç”¨æ¨¡å‹: ${availableModels || 'æ— '}`
          };
        }
      }

      // å¦‚æœ OpenAI API å¤±è´¥ï¼Œå°è¯•æ ‡å‡†çš„ Ollama API
      const ollamaUrl = OllamaService.buildTagsUrl(baseUrl);
      const ollamaResult = await OllamaService.tryFetchWithTimeout(ollamaUrl);
      
      if (ollamaResult.success && ollamaResult.response) {
        const data = await ollamaResult.response.json();
        const models = data.models || [];
        
        const modelExists = models.some((model: { name: string }) => model.name === modelName);
        
        if (modelExists) {
          return { success: true, content: 'æ¨¡å‹å¯ç”¨ (Ollama API)' };
        } else {
          const availableModels = models.map((model: { name: string }) => model.name).join(', ');
          return {
            success: false,
            error: `æ¨¡å‹ '${modelName}' ä¸å­˜åœ¨ã€‚å¯ç”¨æ¨¡å‹: ${availableModels || 'æ— '}`
          };
        }
      }

      return {
        success: false,
        error: 'æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨ - API æ ¼å¼ä¸æ”¯æŒ'
      };

    } catch (error) {
      if (error instanceof Error && error.message.includes('æ— æ•ˆçš„æœåŠ¡å™¨URL')) {
        return {
          success: false,
          error: error.message
        };
      }
      
      return {
        success: false,
        error: `æ£€æŸ¥æ¨¡å‹å¯ç”¨æ€§å¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`
      };
    }
  }

  /**
   * è·å–è¯¦ç»†çš„è¿æ¥å»ºè®®ä¿¡æ¯
   * @param baseUrl å½“å‰URL
   * @returns è¯¦ç»†çš„å»ºè®®å­—ç¬¦ä¸²
   */
  private static getConnectionSuggestion(baseUrl: string): string {
    try {
      const url = new URL(baseUrl);
      const currentPort = url.port || (url.protocol === 'https:' ? '443' : '80');
      const isLocalhost = url.hostname === 'localhost' || url.hostname === '127.0.0.1';
      
      const suggestions = [];
      
      if (!isLocalhost) {
        suggestions.push(`è®¾ç½®ç¯å¢ƒå˜é‡: export OLLAMA_URL=${baseUrl}`);
        suggestions.push('é‡å¯å¼€å‘æœåŠ¡å™¨: npm run dev');
      }
      
      if (currentPort !== '11434') {
        suggestions.push(`å°è¯•é»˜è®¤ç«¯å£: ${url.protocol}//${url.hostname}:11434`);
      }
      
      suggestions.push('ç¡®è®¤ Ollama æœåŠ¡å·²å¯åŠ¨: ollama serve');
      suggestions.push('æ£€æŸ¥ Ollama æœåŠ¡çŠ¶æ€: ollama list');
      
      return `\nå»ºè®®è§£å†³æ–¹æ¡ˆ:\n${suggestions.map((s, i) => `${i + 1}. ${s}`).join('\n')}`;
    } catch {
      return '\nå»ºè®®: è¯·æ£€æŸ¥ URL æ ¼å¼æ˜¯å¦æ­£ç¡®';
    }
  }

  /**
   * æ„é€  OpenAI å…¼å®¹çš„ Models API URL
   * @param baseUrl åŸºç¡€URL
   * @returns å®Œæ•´çš„ OpenAI Models API URL
   */
  private static buildOpenAIModelsUrl(baseUrl: string): string {
    try {
      // åœ¨å¼€å‘ç¯å¢ƒä¸­ï¼Œä¼˜å…ˆä½¿ç”¨ä»£ç†ä»¥é¿å… CORS é—®é¢˜
      if (import.meta.env.DEV) {
        return '/api/ollama/v1/models';
      }
      
      const url = new URL(baseUrl);
      const pathname = url.pathname.endsWith('/') ? url.pathname : url.pathname + '/';
      url.pathname = pathname + 'v1/models';
      return url.toString();
    } catch (error) {
      throw new Error(`æ— æ•ˆçš„æœåŠ¡å™¨URL: ${baseUrl}`);
    }
  }

  /**
   * æ„é€  Tags API URL (æ ‡å‡† Ollama API)
   * @param baseUrl åŸºç¡€URL
   * @returns å®Œæ•´çš„ Tags API URL
   */
  private static buildTagsUrl(baseUrl: string): string {
    try {
      // åœ¨å¼€å‘ç¯å¢ƒä¸­ï¼Œä¼˜å…ˆä½¿ç”¨ä»£ç†ä»¥é¿å… CORS é—®é¢˜
      if (import.meta.env.DEV) {
        return '/api/ollama/api/tags';
      }
      
      const url = new URL(baseUrl);
      const pathname = url.pathname.endsWith('/') ? url.pathname : url.pathname + '/';
      url.pathname = pathname + 'api/tags';
      return url.toString();
    } catch (error) {
      throw new Error(`æ— æ•ˆçš„æœåŠ¡å™¨URL: ${baseUrl}`);
    }
  }

  /**
   * è°ƒç”¨AI API - æ”¯æŒå¤šç§APIæ ¼å¼ï¼Œå¸¦æ™ºèƒ½è¿æ¥ç­–ç•¥
   * @param baseUrl æœåŠ¡å™¨URL
   * @param requestData è¯·æ±‚æ•°æ®
   * @returns APIå“åº”ç»“æœ
   */
  private static async callOllamaAPI(
    baseUrl: string,
    requestData: AIReportRequest
  ): Promise<GenerateReportResult> {
    try {
      // åœ¨å¼€å‘ç¯å¢ƒä¸­ï¼Œä¼˜å…ˆå°è¯•ä»£ç†è¿æ¥
      if (import.meta.env.DEV) {
        console.log('ğŸ¯ æ™ºèƒ½è¿æ¥ç­–ç•¥: ä¼˜å…ˆå°è¯•ä»£ç†è¿æ¥');
        
        // å…ˆå°è¯• OpenAI å…¼å®¹çš„ chat/completions ç«¯ç‚¹ (é€šè¿‡ä»£ç†)
        const openaiResult = await OllamaService.tryOpenAIAPI(baseUrl, requestData);
        if (openaiResult.success) {
          console.log('âœ… ä»£ç†è¿æ¥æˆåŠŸ (OpenAI API)');
          return openaiResult;
        }

        // å¦‚æœå¤±è´¥ï¼Œå°è¯•æ ‡å‡†çš„ Ollama generate ç«¯ç‚¹ (é€šè¿‡ä»£ç†)
        const ollamaResult = await OllamaService.tryOllamaAPI(baseUrl, requestData);
        if (ollamaResult.success) {
          console.log('âœ… ä»£ç†è¿æ¥æˆåŠŸ (Ollama API)');
          return ollamaResult;
        }

        console.log('âš ï¸ ä»£ç†è¿æ¥å¤±è´¥ï¼Œå°è¯•ç›´æ¥è¿æ¥...');
        return OllamaService.tryDirectConnection(baseUrl, requestData);
      }

      // ç”Ÿäº§ç¯å¢ƒæˆ–éå¼€å‘ç¯å¢ƒï¼šç›´æ¥è¿æ¥
      const openaiResult = await OllamaService.tryOpenAIAPI(baseUrl, requestData);
      if (openaiResult.success) {
        return openaiResult;
      }

      const ollamaResult = await OllamaService.tryOllamaAPI(baseUrl, requestData);
      if (ollamaResult.success) {
        return ollamaResult;
      }

      return {
        success: false,
        error: `APIè°ƒç”¨å¤±è´¥ - OpenAIé”™è¯¯: ${openaiResult.error}, Ollamaé”™è¯¯: ${ollamaResult.error}`
      };

    } catch (error) {
      return {
        success: false,
        error: `APIè°ƒç”¨å¼‚å¸¸: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`
      };
    }
  }

  /**
   * å°è¯•ç›´æ¥è¿æ¥ï¼ˆé™çº§ç­–ç•¥ï¼‰
   * @param baseUrl æœåŠ¡å™¨URL
   * @param requestData è¯·æ±‚æ•°æ®
   * @returns APIå“åº”ç»“æœ
   */
  private static async tryDirectConnection(
    baseUrl: string,
    requestData: AIReportRequest
  ): Promise<GenerateReportResult> {
    console.log('ğŸ”„ å°è¯•ç›´æ¥è¿æ¥åˆ°:', baseUrl);
    
    // ä½¿ç”¨ç›´æ¥è¿æ¥æ–¹å¼ï¼ˆç»•è¿‡ç¯å¢ƒæ£€æµ‹ï¼‰
    try {
      // å…ˆå°è¯• OpenAI å…¼å®¹çš„ API (æ„é€ ç›´æ¥URL)
      const openaiUrl = OllamaService.buildDirectOpenAIChatUrl(baseUrl);
      const openaiResult = await OllamaService.tryDirectAPICall(openaiUrl, {
        model: requestData.model,
        messages: [{ role: "user", content: requestData.prompt }],
        temperature: requestData.temperature,
        stream: false
      }, 'openai');
      
      if (openaiResult.success) {
        console.log('âœ… ç›´æ¥è¿æ¥æˆåŠŸ (OpenAI API)');
        return openaiResult;
      }

      // å°è¯•æ ‡å‡† Ollama API (æ„é€ ç›´æ¥URL)
      const ollamaUrl = OllamaService.buildDirectApiUrl(baseUrl);
      const ollamaResult = await OllamaService.tryDirectAPICall(ollamaUrl, requestData, 'ollama');
      
      if (ollamaResult.success) {
        console.log('âœ… ç›´æ¥è¿æ¥æˆåŠŸ (Ollama API)');
        return ollamaResult;
      }

      return {
        success: false,
        error: `ç›´æ¥è¿æ¥å¤±è´¥ - å¯èƒ½æ˜¯ CORS é™åˆ¶æˆ–æœåŠ¡ä¸å¯è¾¾ã€‚å»ºè®®è®¾ç½®ç¯å¢ƒå˜é‡ OLLAMA_URL=${baseUrl} å¹¶é‡å¯å¼€å‘æœåŠ¡å™¨`
      };
    } catch (error) {
      return {
        success: false,
        error: `ç›´æ¥è¿æ¥å¼‚å¸¸: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`
      };
    }
  }

  /**
   * å°è¯• OpenAI å…¼å®¹çš„ API è°ƒç”¨
   */
  private static async tryOpenAIAPI(baseUrl: string, requestData: AIReportRequest): Promise<GenerateReportResult> {
    try {
      const url = OllamaService.buildOpenAIChatUrl(baseUrl);
      
      // è½¬æ¢ä¸º OpenAI æ ¼å¼çš„è¯·æ±‚ä½“
      const openaiRequestData = {
        model: requestData.model,
        messages: [
          {
            role: "user",
            content: requestData.prompt
          }
        ],
        temperature: requestData.temperature,
        stream: false
      };

      const controller = new AbortController();
      const timeoutId = setTimeout(() => {
        controller.abort();
      }, OllamaService.DEFAULT_TIMEOUT);

      const response = await fetch(url, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(openaiRequestData),
        signal: controller.signal
      });

      clearTimeout(timeoutId);

      if (!response.ok) {
        const errorText = await response.text().catch(() => '');
        return {
          success: false,
          error: `HTTP ${response.status}: ${errorText}`
        };
      }

      const responseData = await response.json();
      
      // OpenAI æ ¼å¼çš„å“åº”è§£æ
      if (responseData.choices && responseData.choices[0] && responseData.choices[0].message) {
        return {
          success: true,
          content: responseData.choices[0].message.content
        };
      }

      return {
        success: false,
        error: 'OpenAI API å“åº”æ ¼å¼æ— æ•ˆ'
      };

    } catch (error) {
      if (error instanceof Error) {
        if (error.name === 'AbortError') {
          return { success: false, error: 'è¯·æ±‚è¶…æ—¶' };
        }
        if (error.message.includes('fetch')) {
          return { success: false, error: 'ç½‘ç»œè¿æ¥å¤±è´¥' };
        }
      }
      return {
        success: false,
        error: error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'
      };
    }
  }

  /**
   * å°è¯•æ ‡å‡†çš„ Ollama API è°ƒç”¨
   */
  private static async tryOllamaAPI(baseUrl: string, requestData: AIReportRequest): Promise<GenerateReportResult> {
    try {
      const url = OllamaService.buildApiUrl(baseUrl);
      
      const controller = new AbortController();
      const timeoutId = setTimeout(() => {
        controller.abort();
      }, OllamaService.DEFAULT_TIMEOUT);

      const response = await fetch(url, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(requestData),
        signal: controller.signal
      });

      clearTimeout(timeoutId);

      if (!response.ok) {
        const errorText = await response.text().catch(() => '');
        return {
          success: false,
          error: `HTTP ${response.status}: ${errorText}`
        };
      }

      const responseData: AIReportResponse = await response.json();
      
      if (!responseData.response) {
        return {
          success: false,
          error: 'Ollama API å“åº”æ ¼å¼æ— æ•ˆ'
        };
      }

      return {
        success: true,
        content: responseData.response
      };

    } catch (error) {
      if (error instanceof Error) {
        if (error.name === 'AbortError') {
          return { success: false, error: 'è¯·æ±‚è¶…æ—¶' };
        }
        if (error.message.includes('fetch')) {
          return { success: false, error: 'ç½‘ç»œè¿æ¥å¤±è´¥' };
        }
      }
      return {
        success: false,
        error: error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'
      };
    }
  }

  /**
   * æ„é€  OpenAI å…¼å®¹çš„ Chat Completions API URL
   * @param baseUrl åŸºç¡€URL
   * @returns å®Œæ•´çš„ OpenAI Chat API URL
   */
  private static buildOpenAIChatUrl(baseUrl: string): string {
    try {
      console.log('ğŸ”§ buildOpenAIChatUrl è°ƒè¯•ä¿¡æ¯:', {
        baseUrl,
        isDev: import.meta.env.DEV,
        mode: import.meta.env.MODE
      });
      
      // åœ¨å¼€å‘ç¯å¢ƒä¸­ï¼Œä¼˜å…ˆä½¿ç”¨ä»£ç†ä»¥é¿å… CORS é—®é¢˜
      if (import.meta.env.DEV) {
        const apiPath = '/api/ollama/v1/chat/completions';
        console.log(`âœ… ä½¿ç”¨ä»£ç†è·¯å¾„: ${apiPath} (åŸºäºç”¨æˆ·é…ç½®: ${baseUrl})`);
        return apiPath;
      }
      
      const url = new URL(baseUrl);
      const pathname = url.pathname.endsWith('/') ? url.pathname : url.pathname + '/';
      url.pathname = pathname + 'v1/chat/completions';
      const directUrl = url.toString();
      console.log('ğŸŒ ä½¿ç”¨ç›´æ¥URL:', directUrl);
      return directUrl;
    } catch (error) {
      console.error('âŒ buildOpenAIChatUrl é”™è¯¯:', error);
      throw new Error(`æ— æ•ˆçš„æœåŠ¡å™¨URL: ${baseUrl}`);
    }
  }

  /**
   * æ„é€ API URL (æ ‡å‡† Ollama API)
   * @param baseUrl åŸºç¡€URL
   * @returns å®Œæ•´çš„API URL
   */
  private static buildApiUrl(baseUrl: string): string {
    try {
      console.log('ğŸ”§ buildApiUrl è°ƒè¯•ä¿¡æ¯:', {
        baseUrl,
        isDev: import.meta.env.DEV,
        mode: import.meta.env.MODE
      });
      
      // åœ¨å¼€å‘ç¯å¢ƒä¸­ï¼Œä¼˜å…ˆä½¿ç”¨ä»£ç†ä»¥é¿å… CORS é—®é¢˜
      if (import.meta.env.DEV) {
        const apiPath = '/api/ollama/api/generate';
        console.log(`âœ… ä½¿ç”¨ä»£ç†è·¯å¾„: ${apiPath} (åŸºäºç”¨æˆ·é…ç½®: ${baseUrl})`);
        return apiPath;
      }
      
      const url = new URL(baseUrl);
      // ç¡®ä¿è·¯å¾„ä»¥/ç»“å°¾ï¼Œç„¶åæ·»åŠ api/generate
      const pathname = url.pathname.endsWith('/') ? url.pathname : url.pathname + '/';
      url.pathname = pathname + 'api/generate';
      const directUrl = url.toString();
      console.log('ğŸŒ ä½¿ç”¨ç›´æ¥URL:', directUrl);
      return directUrl;
    } catch (error) {
      console.error('âŒ buildApiUrl é”™è¯¯:', error);
      throw new Error(`æ— æ•ˆçš„æœåŠ¡å™¨URL: ${baseUrl}`);
    }
  }

  /**
   * æ„é€ ç›´æ¥è¿æ¥çš„ OpenAI Chat URL
   */
  private static buildDirectOpenAIChatUrl(baseUrl: string): string {
    const url = new URL(baseUrl);
    const pathname = url.pathname.endsWith('/') ? url.pathname : url.pathname + '/';
    url.pathname = pathname + 'v1/chat/completions';
    return url.toString();
  }

  /**
   * æ„é€ ç›´æ¥è¿æ¥çš„ Ollama API URL
   */
  private static buildDirectApiUrl(baseUrl: string): string {
    const url = new URL(baseUrl);
    const pathname = url.pathname.endsWith('/') ? url.pathname : url.pathname + '/';
    url.pathname = pathname + 'api/generate';
    return url.toString();
  }

  /**
   * å°è¯•ç›´æ¥ API è°ƒç”¨
   */
  private static async tryDirectAPICall(
    url: string,
    requestData: unknown,
    apiType: 'openai' | 'ollama'
  ): Promise<GenerateReportResult> {
    try {
      const controller = new AbortController();
      const timeoutId = setTimeout(() => {
        controller.abort();
      }, OllamaService.DEFAULT_TIMEOUT);

      const response = await fetch(url, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(requestData),
        signal: controller.signal
      });

      clearTimeout(timeoutId);

      if (!response.ok) {
        const errorText = await response.text().catch(() => '');
        return {
          success: false,
          error: `HTTP ${response.status}: ${errorText}`
        };
      }

      const responseData = await response.json();
      
      if (apiType === 'openai') {
        // OpenAI æ ¼å¼çš„å“åº”è§£æ
        if (responseData.choices && responseData.choices[0] && responseData.choices[0].message) {
          return {
            success: true,
            content: responseData.choices[0].message.content
          };
        }
        return {
          success: false,
          error: 'OpenAI API å“åº”æ ¼å¼æ— æ•ˆ'
        };
      } else {
        // Ollama æ ¼å¼çš„å“åº”è§£æ
        if (!responseData.response) {
          return {
            success: false,
            error: 'Ollama API å“åº”æ ¼å¼æ— æ•ˆ'
          };
        }
        return {
          success: true,
          content: responseData.response
        };
      }

    } catch (error) {
      if (error instanceof Error) {
        if (error.name === 'AbortError') {
          return { success: false, error: 'è¯·æ±‚è¶…æ—¶' };
        }
        if (error.message.includes('fetch')) {
          return { success: false, error: 'ç½‘ç»œè¿æ¥å¤±è´¥æˆ– CORS é™åˆ¶' };
        }
      }
      return {
        success: false,
        error: error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'
      };
    }
  }

  /**
   * æ£€æŸ¥é…ç½®çš„å®Œæ•´æ€§
   * @param config AIé…ç½®
   * @returns é…ç½®æ˜¯å¦å®Œæ•´
   */
  static isConfigComplete(config: Partial<AIReportConfig> | undefined): config is AIReportConfig {
    if (!config) return false;
    
    return !!(
      config.ollamaUrl &&
      config.modelName &&
      typeof config.temperature === 'number'
    );
  }
}